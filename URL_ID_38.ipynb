{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpPGJcDW5rXCF8QA/MuFFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjan4Kumar/BS4--Text-Extraction-from-website/blob/main/URL_ID_38.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9JF0pMrtppv",
        "outputId": "f86caf3f-5907-4cef-e0f7-dfc126acd04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=573fadc9050ac95cc6a1a716839ecff53f87234c3b6ce8b5efab45f3b638b34c\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib) (0.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install bs4\n",
        "!pip install html5lib\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create BeautifulSoup object\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the article text\n",
        "content = soup.find(\"div\", class_=\"td-post-content\")\n",
        "\n",
        "# Extract the text\n",
        "text = content.get_text().strip()\n",
        "\n",
        "# Split the text into paragraphs\n",
        "paragraphs = text.split(\"\\n\\n\")\n",
        "\n",
        "# Print each paragraph separately\n",
        "for paragraph in paragraphs:\n",
        "    print(paragraph)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtS4EGO6HEu",
        "outputId": "5fe3f5cb-bce9-4fd7-8143-f8d5c40092b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human minds, a fascination in itself carrying the potential of tinkering nature with the pixie dust intelligence, creating and solving the mysteries and wonders with anything but admiration. However, no matter how captivating a human mind can be, it could sometimes be appalled. It could be the hunger or maybe the desire to want more, to go beyond and unravel the limitations, or maybe something like pure greed. Humans have never stopped and always keep evolving when it comes to intelligence and this is what makes them the supreme.\n",
            "Intelligence calls out for supremacy and so, what if there was to evolve something that opposed a challenge to the very human minds, to their capabilities while making them question their own importance among themselves? Artificial Intelligence came as a revolution, havoc when it first came to the light. The concept of making machines does work on their own, like granting machines –The Intelligence.\n",
            "The idea of making machines work like humans came back in the 19s. Back then people didn’t believe in such a thing as making a non-living thing work, think, and carry tasks on its own, not to mention, to actually surpass humans themselves in those skills. The facts are it did. By 1997. The greatest chess player, Garry Kasparov was defeated in a chess game by a machine and this is where exactly, a top skilled human lost to a mere machine created by another who by himself could’ve never defeated him. It was a rule of power, of betterment, of skills, and the granted supremacy. Were AI and Machines just tools? Equipment?  Something that helped an unskilled person with his mind and intelligence creates something that could do the skilled work for him with perfection and precision? Well initially it was, however, as time passed as humans got drawn to the puzzle of AI, a lot changed. Human research went deeper and deeper and as a result, the machines evolved with it.\n",
            "At present, AI & Machines is a growing field. As it develops and improves, it has become a part of the industrial revolution. In industries, most of the laborious work that was once taken care of by humans was now replaced by machines. Naturally, with the evolution in machines, its precision, mass productivity, quality control, time efficiencies, and all the other factors made it a better choice. A choice over humans.\n",
            "This led to fear, a fear of a not-so-distant future, a future where maybe machines will be so evolved that they’ll take over the need of a human employee leading to unemployment. With the population increase around the world, it became the new tech threat for the labor market. Then again… how true is it? Does AI really oppose a threat? Will adapting to technology make millions of people lose their jobs? Will it lead to mass unemployment? Will the machines really surpass humans? Will, the creation take over the creator?\n",
            "No matter how fearful the future with AI may seem, in reality, it is not that scary. Truth is AI is the present reality, it is the key that holds the power to unlock a whole next level of human evolution. Technology is growing. There was a time where technology was just an idea, but today that idea has been implemented, it’s working and is carried out. Nobody could stop the advancement and growth of Artificial Intelligence, it’s a wave that is already flowing and we as the present generation and the generations to come to have to learn, to learn to swim in this flow and avoid drowning.\n",
            "Many jobs will be replaced by machines, as AI evolves it’ll keep challenging human minds and their skills. With the present COVID 19 situation, contactless cashiers to robots delivering packages have already taken over the usual routine tasks. The jobs of Secretaries, Schedulers, and book-keeper are at risk too. Manufacturing units, agriculture, food services, retail, transportation & logistic, and hospitality are all a part of the AI-affected automation. At an estimation, it is said that around 20 million jobs, especially including manufacturing will be lost to robots. As AI, robotics, 3D printing, and genetics make their way in, even the architects, medical docs, and music composers feel threatened by technology. Making us question that will AI even edge us out of our brain jobs too? Now that can be terrifying.\n",
            "However, as much as machines will be replacing few jobs, they’ll also be creating new jobs.  With the economic growth, innovation, and investment around 133 million jobs are said to be generated. These newly enhanced jobs are to create benefits and amplify one’s creativity, strategy, and entrepreneurial skills. So what is the catch?\n",
            "Well, it’s the skills. Even though AI is creating 3 times more jobs than it is destroying, it’s the skills that count. AI surged in new job opportunities, opportunities like Senior Data Scientist, Mobile Application Developer, and SEO specialist. These jobs were once never heard of but now with AI it’s born, however, to do these jobs or for its qualification, one needs high-level skills and to acquire those skills can be an expensive and time-consuming task. The future generation might be able to cope up with it but the real struggle is to be faced by the present two generations. It’s the vulnerability between the skill gap and unemployment and the youths are the ones to be crushed the most.\n",
            "Therefore, as the advancement of AI becomes inevitable there remains no choice but to adapt, learn, equip ourselves and grow with it. The companies have to work together to build an AI-ready workplace. They should collaborate with the government, educators, and non-profit organizations and work together to bring out policies that could help understand the technologies’ impacts faster while also providing the employees some security. The economic and business planning should be made considerable for minimizing the impact on local jobs and properly maximizing the opportunities.\n",
            "The employees should be provided with proper tools to carry along with the new opportunities while acquiring AI-based skills for their day-to-day work. New skills should be identified and implemented for the upskilling and continual learning initiatives. Employees will have to maximize their Robotic Quotient and learn core skills. They’ll have to adapt to new working models and understand their roles in the coming future. \n",
            "Howsoever, it’s not like AI will totally take over control, even though AI proves to be a better choice, it still has its limitations at present. First, it’s expensive, secondly, manufacturing machines in bulk is not good for the environment. Machines are also very high maintenance, therefore human labor will often come cheaper and so will be considered over machines. Underdeveloped countries will find it hard to equip their people with the upskilling and reskilling required for AI workplace and so for AI to play a role in those countries, might take years. AI can also be risky and unethical, as it’s hard to figure out who to be held responsible for in cases where an AI went wrong.\n",
            "No matter, how advanced AI gets, there are some skills where humans will always have an upper hand i.e., soft skills. Skills like teamwork, communication, creativity, and critical thinking are something that AI hasn’t been able to beat us up to yet and so the value of creativity, leadership, and emotional intelligence has increased. Although, with machines coming in between humans causing the lack of human-to-human interaction, the humans seem to fade away a little.\n",
            "With this era, comes the need for good leaders. Leaders who are capable of handling both machines and humans together, the ones who are organized enough to manage the skilled and the unskilled employees while providing the unskilled trainees with proper training. Leaders who hold profound soft skills and encourage teamwork while working along with machines. The ones who are patient, calm, and optimized.  \n",
            "In conclusion, yes AI and machines are going to be very challenging but there’s nothing humans haven’t overcome. Adaptation and up-gradation are going to be the primary factor for survival. As we witness the onset of the 4th industrial revolution, let’s buckle up our seats and race along the highway with the essential fuels (skills) so as to not let ourselves eliminated. After all, this is an unending race with infinity as the end, all we could do is try not to run out of fuel. Try not to be outdated. \n",
            "Blackcoffer Insights 29: Glady, Karunya Institute of Technology and Sciences.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cH5mDWog6NUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Stop words files\n",
        "stopword_files = [\n",
        "    \"/content/StopWords_Auditor.txt\",\n",
        "    \"/content/StopWords_Currencies.txt\",\n",
        "    \"/content/StopWords_DatesandNumbers.txt\",\n",
        "    \"/content/StopWords_Generic.txt\",\n",
        "    \"/content/StopWords_GenericLong.txt\",\n",
        "    \"/content/StopWords_Geographic.txt\",\n",
        "    \"/content/StopWords_Names.txt\"\n",
        "]\n",
        "\n",
        "# Load stop words from multiple files\n",
        "stop_words = set()\n",
        "for file in stopword_files:\n",
        "    with open(file, \"r\", errors=\"replace\") as f:\n",
        "        encoding = \"utf-8\"  # Start with UTF-8 encoding\n",
        "        try:\n",
        "            stop_words.update(f.read().splitlines())\n",
        "        except UnicodeDecodeError:\n",
        "            # If UTF-8 fails, try different encodings\n",
        "            encodings_to_try = [\"latin-1\", \"iso-8859-1\"]\n",
        "            for encoding in encodings_to_try:\n",
        "                try:\n",
        "                    with open(file, \"r\", encoding=encoding) as f_retry:\n",
        "                        stop_words.update(f_retry.read().splitlines())\n",
        "                        break\n",
        "                except UnicodeDecodeError:\n",
        "                    pass\n",
        "\n",
        "# Positive and negative words files\n",
        "positive_words_file = '/content/positive-words.txt'\n",
        "negative_words_file = '/content/negative-words.txt'\n",
        "\n",
        "# Load the positive words\n",
        "with open(positive_words_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    positive_words = [word.strip() for word in file.readlines()]\n",
        "\n",
        "# Load the negative words\n",
        "with open(negative_words_file, \"r\", encoding=\"latin-1\") as file:\n",
        "    negative_words = [word.strip() for word in file.readlines()]\n",
        "\n",
        "# Initialize the SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Remove stop words from the text data\n",
        "words = word_tokenize(paragraph.lower())\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "# Create a dictionary of positive and negative words\n",
        "word_sentiment = defaultdict(int)\n",
        "for word in filtered_words:\n",
        "    if word in positive_words:\n",
        "        word_sentiment[word] = 1\n",
        "    elif word in negative_words:\n",
        "        word_sentiment[word] = -1\n",
        "\n",
        "#Applying model on the data\n",
        "sentiment_scores = sia.polarity_scores(paragraph)\n",
        "positive_word_count = sum(value == 1 for value in word_sentiment.values())\n",
        "negative_word_count = sum(value == -1 for value in word_sentiment.values())\n",
        "# TextBlob\n",
        "blob = TextBlob(paragraph)\n",
        "\n",
        "polarity_score = sentiment_scores['compound']\n",
        "subjectivity_score = blob.sentiment.subjectivity\n",
        "avg_sentence_length = len(words) / len(blob.sentences)\n",
        "percentage_complex_words = (len([word for word in filtered_words if len(word) > 2]) / len(filtered_words)) * 100\n",
        "fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "avg_words_per_sentence = len(words) / len(blob.sentences)\n",
        "complex_word_count = len([word for word in filtered_words if len(word) > 2])\n",
        "word_count = len(filtered_words)\n",
        "syllables_per_word = blob.sentiment_assessments.assessments[0][1]\n",
        "personal_pronouns = sum(1 for word in blob.tags if word[1] == 'PRP')\n",
        "avg_word_length = sum(len(word) for word in filtered_words) / len(filtered_words)\n",
        "\n",
        "# Print\n",
        "print(\"positive_word_count:\",positive_word_count)\n",
        "print(\"negative_word_count:\",negative_word_count)\n",
        "print(\"polarity_score:\",polarity_score)\n",
        "print(\"subjectivity_score:\",subjectivity_score)\n",
        "print(\"avg_sentence_length :\",avg_sentence_length )\n",
        "print(\"percentage_complex_words:\",percentage_complex_words)\n",
        "print(\"fog_index:\",fog_index)\n",
        "print(\"avg_words_per_sentence:\",avg_words_per_sentence)\n",
        "print(\"complex_word_count:\",complex_word_count)\n",
        "print(\"word_count:\",word_count)\n",
        "print(\"syllables_per_word\",syllables_per_word)\n",
        "print(\"personal_pronouns:\",personal_pronouns)\n",
        "print(\"avg_word_length\",avg_word_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ki_7HLKuXsM",
        "outputId": "540b0311-099b-4ccc-ac71-31039405c7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive_word_count: 38\n",
            "negative_word_count: 29\n",
            "polarity_score: 0.9984\n",
            "subjectivity_score: 0.43359613375130607\n",
            "avg_sentence_length : 20.5125\n",
            "percentage_complex_words: 70.56694813027744\n",
            "fog_index: 36.43177925211098\n",
            "avg_words_per_sentence: 20.5125\n",
            "complex_word_count: 585\n",
            "word_count: 829\n",
            "syllables_per_word 0.0\n",
            "personal_pronouns: 52\n",
            "avg_word_length 5.344993968636912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZKMPxKz71OF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}