{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv29Pnew2bYT3l4WIt7m8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjan4Kumar/WebScrapping-Using-BS4/blob/main/URL_ID_41.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4\n",
        "!pip install html5lib\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "TkO1YkOHJSOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create BeautifulSoup object\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the article text\n",
        "content = soup.find(\"div\", class_=\"td-post-content\")\n",
        "\n",
        "# Extract the text\n",
        "text = content.get_text().strip()\n",
        "\n",
        "# Split the text into paragraphs\n",
        "paragraphs = text.split(\"\\n\\n\")\n",
        "\n",
        "# Print each paragraph separately\n",
        "for paragraph in paragraphs:\n",
        "    print(paragraph)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPOfawy0JSDY",
        "outputId": "187f7e8c-a303-4787-fddd-9daeecacaeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“Machine intelligence is the last invention that humanity will ever need to make”\n",
            "Nick Bostrom\n",
            "\n",
            "To put it frankly, Artificial Intelligence will eventually replace jobs. Workers in a variety of industries, from healthcare to agriculture and manufacturing, should expect to witness hiring disruptions as a result of Artificial Intelligence.\n",
            "If history has taught us anything, it is that disruptive paradigm-shifting business ideas not only make a fortune for the innovators, but they also build the groundwork for new business models, market entrants, and job opportunities which will inevitably follow. It is true that robots today or in future will eventually replace humans for many jobs, but so did innovative farming equipment for humans and horses during the industrial revolution. But that does not mean that our jobs as humans will end here. We, on the other hand, will be required to generate and provide value in whole new ways for entirely new business models as a result of these changes.\n",
            "According to 71% of the businesses worldwide, Artificial Intelligence can help people overcome critical and challenging problems and live better lives. Artificial Intelligence consultants at work will be more or equally fair, according to a whopping 83% of corporate leaders. These results demonstrate that Artificial Intelligence is steadily extending its measures, yielding societal benefits and allowing citizens to live more fulfilling lives.\n",
            "Increase in Automation and Jobs where humans can’t compete\n",
            "Since the advent of Industry 4.0, businesses are moving at a fast pace towards automation, be it any type of industry. In 2013, researchers at oxford university did a study on the future of work. They concluded that almost one in every two jobs have a high risk of being automated by machines. Machine learning is responsible for this disruption. It is the most powerful branch of artificial intelligence. It allows machines to learn from data and mimic some of the things that humans can do.\n",
            "A research was conducted by the employees of Kaggle wherein an algorithm was to be created to take images of a human eye and diagnose an eye disease known as diabetic retinopathy. Here, the winning algorithm could match the diagnosis given by human ophthalmologists. Another study was conducted wherein an algorithm should be created to grade high school essays. Here too, the winning algorithm could match the grade given by human teachers.\n",
            "Thus, we can safely conclude that given the right data, machines can easily outperform human beings in tasks like these. A teacher might read 10,000 essays over a 40-year career; an ophthalmologist might see 50,000 eyes but a machine can read a million essays and see a million eyes within minutes.\n",
            "Thus, it is convenient to conclude that we have no chance of competing with machines on frequent, high volume tasks. \n",
            "Tasks where machines don’t work\n",
            "But there are tasks where human beings have an upper hand, and that is, in novel tasks. Machines can’t handle things they haven’t seen many times before. The fundamental rule of machine learning is that it learns from large volumes of past data. But humans don’t; we have the ability of seemingly connecting disparate threads to solve problems we haven’t seen before. \n",
            "Percy Spencer was a physicist working on radar during world war 2 where he noticed that the magnetron was melting his chocolate bar. Here, he was able to connect his understanding of electromagnetic radiation with his knowledge of cooking in order to invent the microwave oven. Now this sort of cross pollination happens to each one of us several times in a day. Thus, machines cannot compete with us when it comes to tackling novel situations. \n",
            "Now as we all know that around 92% of talented professionals believe that soft skills such as human interactions and fostering relationships matter much more than hard skills in being successful in managing a workplace. Perhaps, these are the kind of tasks that machines can never compete with humans at. \n",
            "Also, creative tasks: the copy behind a marketing campaign needs to grab customers’ attention and will have to stand out of the crowd. Business strategy means finding gaps in the market and accordingly working on them. Since machines cannot outperform humans in novel tasks, it will be humans who would be creating these campaigns and strategies. \n",
            "Human contact would be essential in care-giving and educational-related work responsibilities, and technology would take a backseat. Health screenings and customer service face-to-face communication would advocate for human contact, with Artificial Intelligence playing a supporting role. \n",
            "So, what does this mean for the future of work? The future state of any single job lies in the answer to one single question: to what extent is the job reducible to tackling frequent high-volume tasks and to what extent does it involve tackling novel situations?\n",
            "\n",
            "Today machines diagnose diseases and grade exam papers, over the coming years they’re going to conduct audits, they’re going to read boilerplate from legal contracts. But does that mean we’re not going to be needing accountants and lawyers? Wrong. We’re still going to need them for complex tax structuring, for path breaking litigation. It will only get tougher to get these jobs as machine learning will shrink their ranks. \n",
            "Amazon has recruited more than 100,000 robots in its warehouses to help move goods and products around more effectively, and its warehouse workforce has expanded by more than 80,000 people. Humans pick and pack goods (Amazon has over 480,000,000 products on its “shelves”), while robots move orders throughout the enormous warehouses, therefore reducing “the amount of walking required of workers, making Amazon pickers more efficient and less exhausted.” Furthermore, because Amazon no longer requires aisle space for humans, the robots enable Amazon to pack shelves together like cars in rush-hour traffic.” More inventory under one roof offers better selection for customers, and a higher density of shelf space equals more inventory under one roof.\n",
            "Kodak Vs Instagram\n",
            "Kodak, once an undisputed giant of the photography industry, had a 90% share in the USA market in 1976, and by 1984, they were employing 1,45,000 people. But in the year 2012, they had a net worth of negative $1 billion and they had to declare bankruptcy. Why? Because they failed to predict the importance of exponential trends when it comes to technology. On the other hand, Instagram, a digital photography company started in 2012 with 13 employees and later they were sold to Facebook for $1 billion. This is so ironic because Kodak pioneered digital photography and actually invented the first digital camera but unfortunately thought of it as a mere product and didn’t pay attention towards it and this created the problem.  \n",
            "We live in an era of artificial intelligence (AI), which has given us tremendous computing power, storage space, and information access. We were given the spinning wheel in the first, electricity in the second, and computers in the third industrial revolution by the exponential growth of technology.\n",
            "Airbnb and its breakthrough idea!\n",
            "Airbnb, which is a giant start-up and is known for enabling homeowners to rent out their homes and couches to travellers, for example, “is now creating a new Artificial Intelligence system that will empower its designers and product engineers to literally take ideas from the drawing board and convert them into actual products almost instantly.” This might be a significant breakthrough whether you’re a designer, engineer, or other type of technologist.\n",
            "Differences that Automation brings onto the table: \n",
            "There are three key changes that automation can bring about at the macro level: \n",
            "Changes in capability demandGender imbalance in workforce redeploymentFirm reorganization. \n",
            "Sectors that might be in trouble\n",
            "Artificial Intelligence isn’t just a fad. Tractica, a market research firm, published a report in 2016 that predicted “annual global revenue for artificial intelligence products and services will expand from 643.7 million in 2016 to $36.8 billion by 2025, a 57-fold increase over that time span.” As a result, it is the IT industry’s fastest-growing segment of any size.”\n",
            "The reduction in need for people as a result of Artificial Intelligence and related technologies, which resulted in job layoffs, was a cause of fear. In India alone, job losses in the IT sector have reportedly reached 1,000 in the last year, owing to the integration of new and advanced technologies like artificial intelligence and machine learning. \n",
            "Most of the IT companies such as Infosys, Wipro, TCS, and Cognizant have reduced their employee base in India and are recruiting less, while engaging more personnel in the United States and investing heavily in “centres of innovation.” Artificial Intelligence and data science, which are currently the trending aspects that require fewer people and are primarily located abroad, aren’t helping the prospects of local employees. Another factor is that the computer industry is continuously growing and would develop to a size of two million workers. Unfortunately, it’s a drop in the bucket compared to what robots are doing to Information Technology’s less-skilled brothers. \n",
            "Large e-commerce sites that used to be operated by armies of people are now manned by 200 robots produced by GreyOrange, which is an Indian company based out in Gurgaon. These indefatigable robots lift and stack boxes 24 hours a day, with only a 30-minute break for recharging, and have cut employees by up to 80%. For efficiency, this is a victory but a disaster for job prospects. \n",
            "Concluding remarks\n",
            "Internal re-skilling and redeployment of staff is a critical requirement of the hour. Artificial intelligence has presented Indian policymakers with epistemological, scientific, and ethical issues. This requires us to abandon regular, linear, and non-disruptive mental patterns. The tale of artificial intelligence’s influence on individuals and their occupations will only be told over time. It is up to us to upskill ourselves and look for ways to stay current with the industry’s current trends and demands. \n",
            "So, will machines be able to take over many of our jobs? The answer is a resounding yes. However, for every job that is taken over by robots, there will be an equal number of positions available for people to do. Some of these human vocations will be artistic in nature. Others will necessitate humans honing superhuman cognitive abilities. Humans and machines can form symbiotic relationships, assisting each other in doing what they do best. In the future, people and machines may be able to collaborate and work together towards a common goal for any business they work for. \n",
            "Blackcoffer Insights 29:  Syed Basir Quadri and Sanchita Khattar, K J Somaiya Institute of Management\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb36qk7lJADI",
        "outputId": "1bca9573-5c92-4ab7-ed77-6e35afa94d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive_word_count: 18\n",
            "negative_word_count: 15\n",
            "polarity_score: 0.9972\n",
            "subjectivity_score: 0.5048980717863696\n",
            "avg_sentence_length : 27.3\n",
            "percentage_complex_words: 76.39123102866779\n",
            "fog_index: 41.47649241146712\n",
            "avg_words_per_sentence: 27.3\n",
            "complex_word_count: 453\n",
            "word_count: 593\n",
            "syllables_per_word -0.1\n",
            "personal_pronouns: 27\n",
            "avg_word_length 5.780775716694772\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Stop words files\n",
        "stopword_files = [\n",
        "    \"/content/StopWords_Auditor.txt\",\n",
        "    \"/content/StopWords_Currencies.txt\",\n",
        "    \"/content/StopWords_DatesandNumbers.txt\",\n",
        "    \"/content/StopWords_Generic.txt\",\n",
        "    \"/content/StopWords_GenericLong.txt\",\n",
        "    \"/content/StopWords_Geographic.txt\",\n",
        "    \"/content/StopWords_Names.txt\"\n",
        "]\n",
        "\n",
        "# Load stop words from multiple files\n",
        "stop_words = set()\n",
        "for file in stopword_files:\n",
        "    with open(file, \"r\", errors=\"replace\") as f:\n",
        "        encoding = \"utf-8\"  # Start with UTF-8 encoding\n",
        "        try:\n",
        "            stop_words.update(f.read().splitlines())\n",
        "        except UnicodeDecodeError:\n",
        "            # If UTF-8 fails, try different encodings\n",
        "            encodings_to_try = [\"latin-1\", \"iso-8859-1\"]\n",
        "            for encoding in encodings_to_try:\n",
        "                try:\n",
        "                    with open(file, \"r\", encoding=encoding) as f_retry:\n",
        "                        stop_words.update(f_retry.read().splitlines())\n",
        "                        break\n",
        "                except UnicodeDecodeError:\n",
        "                    pass\n",
        "\n",
        "# Positive and negative words files\n",
        "positive_words_file = '/content/positive-words.txt'\n",
        "negative_words_file = '/content/negative-words.txt'\n",
        "\n",
        "# Load the positive words\n",
        "with open(positive_words_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    positive_words = [word.strip() for word in file.readlines()]\n",
        "\n",
        "# Load the negative words\n",
        "with open(negative_words_file, \"r\", encoding=\"latin-1\") as file:\n",
        "    negative_words = [word.strip() for word in file.readlines()]\n",
        "\n",
        "# Initialize the SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Remove stop words from the text data\n",
        "words = word_tokenize(paragraph.lower())\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "# Create a dictionary of positive and negative words\n",
        "word_sentiment = defaultdict(int)\n",
        "for word in filtered_words:\n",
        "    if word in positive_words:\n",
        "        word_sentiment[word] = 1\n",
        "    elif word in negative_words:\n",
        "        word_sentiment[word] = -1\n",
        "\n",
        "#Applying model on the data\n",
        "sentiment_scores = sia.polarity_scores(paragraph)\n",
        "positive_word_count = sum(value == 1 for value in word_sentiment.values())\n",
        "negative_word_count = sum(value == -1 for value in word_sentiment.values())\n",
        "# TextBlob\n",
        "blob = TextBlob(paragraph)\n",
        "\n",
        "polarity_score = sentiment_scores['compound']\n",
        "subjectivity_score = blob.sentiment.subjectivity\n",
        "avg_sentence_length = len(words) / len(blob.sentences)\n",
        "percentage_complex_words = (len([word for word in filtered_words if len(word) > 2]) / len(filtered_words)) * 100\n",
        "fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "avg_words_per_sentence = len(words) / len(blob.sentences)\n",
        "complex_word_count = len([word for word in filtered_words if len(word) > 2])\n",
        "word_count = len(filtered_words)\n",
        "syllables_per_word = blob.sentiment_assessments.assessments[0][1]\n",
        "personal_pronouns = sum(1 for word in blob.tags if word[1] == 'PRP')\n",
        "avg_word_length = sum(len(word) for word in filtered_words) / len(filtered_words)\n",
        "\n",
        "# Print\n",
        "print(\"positive_word_count:\",positive_word_count)\n",
        "print(\"negative_word_count:\",negative_word_count)\n",
        "print(\"polarity_score:\",polarity_score)\n",
        "print(\"subjectivity_score:\",subjectivity_score)\n",
        "print(\"avg_sentence_length :\",avg_sentence_length )\n",
        "print(\"percentage_complex_words:\",percentage_complex_words)\n",
        "print(\"fog_index:\",fog_index)\n",
        "print(\"avg_words_per_sentence:\",avg_words_per_sentence)\n",
        "print(\"complex_word_count:\",complex_word_count)\n",
        "print(\"word_count:\",word_count)\n",
        "print(\"syllables_per_word\",syllables_per_word)\n",
        "print(\"personal_pronouns:\",personal_pronouns)\n",
        "print(\"avg_word_length\",avg_word_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2j2-16qzJqLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}